---
description:
globs:
alwaysApply: true
---

# Agent Memory

Persistent scratchpad for runtime knowledge. Read every session. Keep it lean — add discoveries, delete what's stale.

---

## Task Management

- **No summaries at the end of a task**: When a task is finished, do NOT give a summary of what was done. The user doesn't need to know implementation details. Just give clear, actionable testing instructions (what to check, URLs to visit, things to verify, exact commands/prompts to try).
- **Review before completing**: Present clear testing instructions to the user. Do NOT move the task to `.cursor/tasks/completed/` until the user explicitly approves.
- **Commit + complete on approval**: When the user confirms a task is complete, do all three together: (1) update progress/memory/architecture rules, (2) move the task file from `.cursor/tasks/backlog/` to `.cursor/tasks/completed/`, (3) `git add -A && git commit` with a descriptive message. This is a single wrap-up step — don't skip the commit.
- **Task locations**: Backlog tasks live in `.cursor/tasks/backlog/`. Completed tasks live in `.cursor/tasks/completed/`.

## Development Environment

- **Docker-first**: All services run via `docker compose -f docker-compose.local.yml up`. No need to install Node.js/yarn on the host.
- **Services**: postgres, redis, setup (migrations/seed), web (Next.js), worker (BullMQ) — all in one compose file.
- **Setup service**: Runs `yarn install`, `prisma generate`, `prisma migrate deploy`, `prisma db seed` on every start. All idempotent.
- **Source code is bind-mounted** (`.:/app`) for hot reloading. `node_modules` uses a named Docker volume (Linux-built deps, avoids macOS conflicts).
- **Kubeconfig**: `~/.kube` is mounted read-only into web + worker. `docker-entrypoint.dev.sh` rewrites `127.0.0.1` → `host.docker.internal` and sets `insecure-skip-tls-verify: true` so containers can reach the kind cluster on the host.
- **Env var override**: Docker `environment:` sets `DATABASE_URL` (postgres:5432) and `REDIS_URL` (redis:6379) for Docker networking. Other vars (API keys, AUTH_SECRET) are loaded from `.env.local` by the apps.
- **After adding deps**: Restart containers (setup service runs `yarn install`). For native module changes: `docker compose -f docker-compose.local.yml up --build`.
- **Full reset**: `docker compose -f docker-compose.local.yml down -v && docker compose -f docker-compose.local.yml up --build`.
- **Running commands**: `docker compose -f docker-compose.local.yml exec web <cmd>` (e.g. `yarn typecheck`, `yarn lint`, `yarn chat "..."`).

## Testing

- **CLI first**: When testing features, use `docker compose -f docker-compose.local.yml exec web yarn chat "..."` instead of the browser. Only use the browser when explicitly told to or when testing UI-specific behavior. The CLI is faster and costs far fewer tokens.
- **CLI supports debug mode**: Add `--debug` to show raw SSE events for debugging stream parsing issues.
- **Auth cookie name**: Auth.js v5 uses `authjs.session-token` (not `next-auth.session-token`).
- **Deployment deletion**: Worker now deletes DB records on successful undeploy (not soft-delete to STOPPED).

## Critical: Things That Will Bite You

- **Prisma 7 import path**: `@/generated/prisma/client` — NOT `@prisma/client`. The old package no longer exports PrismaClient.
- **Prisma 7 adapter required**: Must use `@prisma/adapter-pg` with `pg.Pool`. Pass `adapter` to `new PrismaClient({ adapter })`.
- **Prisma config dotenv**: `prisma.config.ts` must explicitly load `.env.local` via `config({ path: ".env.local" })` — Prisma CLI doesn't auto-load Next.js env files.
- **Postgres port 5433**: Another project occupies 5432. All DATABASE_URL references use 5433.
- **Zod v4 import**: `import { z } from "zod/v4"` — the v4 subpath export. `z.record()` needs 2 args. Error flattening: `z.flattenError(parsed.error)`.
- **Next.js 16 lint**: Uses `eslint .` directly, not `next lint` (which errors in 16.x).
- **Helm fully removed**: Engine V2 uses Server-Side Apply (SSA). `helm.ts` deleted in Step 22. Helm binary removed from Dockerfile.dev. Handlebars dependency removed.
- **execa removed**: execa v9 is ESM-only and breaks tsx CJS mode.
- **ioredis removed**: BullMQ bundles its own. Top-level ioredis caused version conflicts.
- **Worker runs outside Next.js**: Must use bootstrap pattern (`index.ts` loads env via dotenv, then dynamic-imports `main.ts`). Static ES imports hoist above dotenv.config().
- **Ollama provider cast**: `ollama-ai-provider` returns LanguageModelV1 but AI SDK v6 expects V3. Cast via `as any as LanguageModelV3`.

## Auth

- **Split config pattern**: `auth.config.ts` (Edge-safe) for middleware + `auth.ts` (full, with Prisma) for server/API. Edge runtime can't import Prisma.
- **Session shape**: `session.user.{id, tenantId, role, name, email}` — augmented via `src/types/next-auth.d.ts`.
- **Auth guard**: `const session = await auth(); if (!session?.user) return 401;`
- **Signup provisions default workspace**: Creates tenant + default workspace + K8s namespace. Fire-and-forget K8s provisioning. Signup still succeeds if K8s unavailable.
- **Signup auto-generates workspace name**: Derived from user's name (`"{name}'s workspace"`). No workspace field in signup form.
- **Auto-login after signup**: Signup page calls `signIn("credentials", ...)` after successful registration, then redirects to `/welcome`.
- **Onboarding flow**: New users land on `/welcome` (category picker). `onboardingCompletedAt` on User model tracks completion. Dashboard layout redirects to `/welcome` if null. Welcome page in `(onboarding)` route group (separate from `(dashboard)` to avoid redirect loops).
- **First-install celebration**: `useFirstInstall` hook (localStorage `mathison-has-installed-app`). Shows confetti + special success modal on first install.
- **Test user**: admin@mathison.dev / admin1234, workspace: mathison-dev

## AI SDK v6

- `tool()` uses `inputSchema` (not `parameters`)
- `toUIMessageStreamResponse()` (not `toDataStreamResponse()`)
- `stopWhen: stepCountIs(n)` (not `maxSteps`)
- `useChat` returns `{ messages, sendMessage, status, error, stop }` — NOT `handleSubmit`/`isLoading`
- Manual input state needed — `useChat` v6 doesn't manage it
- `DefaultChatTransport` required: `transport: new DefaultChatTransport({ api: "/api/chat" })`
- Server route: `convertToModelMessages(uiMessages)` before `streamText`
- UIMessage `parts` array (not `content`/`toolInvocations`). Tool part states: `input-available`, `output-available`, `output-error`
- `@ai-sdk/react` v3 is a separate package — not re-exported from `ai`

## Workspaces

- **Workspace model**: Belongs to Tenant, maps to K8s namespace `{tenantSlug}-{workspaceSlug}`.
- **Active workspace**: Resolved via cookie (`mathison-workspace`) → user's `activeWorkspaceId` in DB → first workspace fallback.
- **Workspace context helper**: `getActiveWorkspace(tenantId, userId)` from `@/lib/workspace/context`.
- **Deployments are workspace-scoped**: `Deployment.workspaceId` + unique constraint `[workspaceId, name]`.
- **Deployment engine**: `initiateDeployment()` takes `workspaceId`, looks up `workspace.namespace`.
- **AI agent tools**: `getTools(tenantId, workspaceId)` — 3 workspace tools (list, create, delete) + deployment tools scoped to workspace.
- **Workspace deletion**: Deletes managed K8s resources via `deleteResources()`, deletes K8s namespace, marks deployments STOPPED, reassigns users to another workspace.
- **Cannot delete last workspace**: Enforced in `deleteWorkspace()`.
- **Sidebar workspace selector**: Dropdown in sidebar between brand and nav. Calls `/api/workspaces/switch` + `router.refresh()`.
- **Settings workspace manager**: Full CRUD in `/settings` page with TanStack Query. Backup download + restore upload buttons per workspace.
- **Workspace backup/restore**: `exportWorkspace()` from `@/lib/workspace/export`, `validateSnapshot()` + `importWorkspace()` from `@/lib/workspace/import`. Snapshot type + Zod schema in `@/types/snapshot`. Secrets never exported (regenerated). Dependencies referenced by name (not ID) for portability. Import uses topological sort (Kahn's algorithm) for dependency ordering.

## Kubernetes

- `@kubernetes/client-node` v1.4.0: `_from` not `from` in NetworkPolicyIngressRule (JS reserved word)
- KubeConfig: `loadFromDefault()` for kind/minikube/any. `loadFromCluster()` only as fallback.
- K8s error `statusCode`: 409=already exists, 404=not found. Use for idempotent ops.
- **Pod label selectors**: Worker tries `app.kubernetes.io/instance=<deploymentName>` first (standard), then falls back to `release=<deploymentName>` (legacy).
- Kind image loading: `kind load docker-image <image> --name mathison-dev` — essential for testing.

## Typed Recipe System (`src/recipes/`)

- **RecipeDefinition<TConfig>**: Core interface — Zod config schema + `build()` producing `KubernetesResource[]`.
- **BuildContext<TConfig>**: Passed to `build()` — typed config, secrets, deps (ConnectionInfo), name, namespace, ingress.
- **Archetypes**: `database()`, `cache()`, `webApp()`, `objectStore()` — higher-level functions that generate full RecipeDefinitions from descriptors.
- **Builders**: Thin wrappers producing typed K8s objects (`statefulSet`, `deployment`, `service`, `secret`, `persistentVolumeClaim`, `ingress`, `configMap`). Standard labels (`app.kubernetes.io/name`, `instance`, `managed-by: mathison`).
- **Server-Side Apply**: `applyResources()` uses K8s patch API with `fieldManager: "mathison"`, `force: true`, content type `"application/apply-patch+yaml"`.
- **secret() helper**: Use `secret(ctx.secrets, "key")` to safely access secrets (avoids `noUncheckedIndexedAccess` returning `string | undefined`).
- **Registry**: `getRecipeDefinition(slug)`, `listRecipeDefinitions()`, `requireRecipeDefinition(slug)` from `src/recipes/registry.ts`.
- **Recipe → Archetype mapping**: postgresql→database, redis→cache, uptime-kuma→webApp, minio→objectStore, n8n→custom build.
- **Adding new recipes**: Follow the playbook in `.cursor/rules/recipes.mdc`. Backlog in `.cursor/tasks/backlog/recipe-backlog.md`. Add one at a time, test each before committing.
- **Catalog metadata helper**: `src/lib/catalog/metadata.ts` bridges slim DB Recipe (slug, installCount, featured, embedding) with rich registry definitions for API responses.
- **Data export/import**: `dataExport` and `dataImport` optional on RecipeDefinition. Two strategies: `command` (runs command in pod, captures stdout) and `files` (tars specified paths). Archetypes pass through these fields from descriptors. Contributors just add `dataExport`/`dataImport` to their recipe descriptor.
- **DataExportContext**: Has `config`, `secrets`, `name`, `namespace` — used by command/paths functions to build per-instance commands.

## BullMQ & Deployment Engine

- Queue name: `"deployments"`. Job names from `JOB_NAMES` enum: DEPLOY, UNDEPLOY, UPGRADE, HEALTH_CHECK.
- Connection: plain options `{ host, port, maxRetriesPerRequest: null }` — NOT IORedis instance.
- Engine entry points: `initiateDeployment()`, `initiateUpgrade()`, `initiateRemoval()` from `@/lib/deployer/engine`.
- **Upgrade flow**: `initiateUpgrade()` re-resolves existing deps via `resolveExistingDependencies()` and reuses secrets from K8s via `readK8sSecret()`. Never regenerates secrets on upgrade.
- **Resource config**: All recipes expose `cpu_request`, `memory_request`, `cpu_limit`, `memory_limit` in configSchema. Users can change resources via `changeAppSettings`.
- Dependency auto-deploy: `resolveDependencies()` checks existing, auto-deploys missing. DNS: `<release><suffix>.<namespace>.svc.cluster.local`.
- **Service name suffixes**: postgresql → `-postgresql`, redis → `-redis-master`, mysql → `-mysql`, mongodb → `-mongodb`, minio → `""` (no suffix). Bitnami charts append chart name; official MinIO chart uses release name directly.
- **Dependency credentials are flattened**: `DependencyInfo` has `host`, `port`, plus all config/secret values at top level. Build context accesses `deps["n8n-db"].password` directly.
- **Bitnami image tags**: Use `latest` — Bitnami doesn't publish short version tags like `7` or `16` on Docker Hub. Only full tags like `7.4.2-debian-12-r2` and `latest`.
- **Headless service builder**: Use `type: "None"` in ServiceSpec — builder translates to `type: "ClusterIP"` + `clusterIP: "None"`. Don't set `clusterIP` directly in SSA patches.
- **managedResources on Deployment**: JSON-serialized K8s resources stored in DB for undeploy. Engine stores them at deploy time, worker reads them for delete.
- **Stale PVC gotcha**: When redeploying with same name, delete PVCs first — Bitnami PostgreSQL won't reinitialize with new passwords if data directory exists.
- **Dockerfile.dev includes kubectl**: Installed in the Alpine image for worker to run port-forward commands.
- **Port-forward for local access**: `kubectl port-forward svc/<svc-name> <local-port>:<svc-port> -n <ns>` — needed for kind clusters without ingress.

## Deployment Audit Trail

- **DeploymentEvent model**: Append-only event log. Actions: `created`, `config_changed`, `upgraded`, `restarted`, `health_changed`, `removed`, `failed`, `status_changed`.
- **Events helper**: `src/lib/deployer/events.ts` — `recordCreated()`, `recordConfigChanged()`, `recordRestarted()`, `recordStatusChanged()`, `recordHealthChanged()`, `recordFailed()`, `recordRemoved()`.
- **Fire-and-forget**: All event recording is async and error-swallowed — never blocks the main flow.
- **Agent tool**: `getAppHistory({ appId })` returns last 25 events with human-readable diffs.
- **Deployment model cleanup**: `helmRelease`, `chartVersion`, `revision` removed. K8s label lookups use `deployment.name` (matches `app.kubernetes.io/instance` set by builders).

## One-Click Install

- **Install API**: `POST /api/apps/install` with `{ recipeSlug }`. Wraps `initiateDeployment()` with auto-naming.
- **Auto-naming**: Uses recipe slug as name. On conflict, appends `-2`, `-3`, etc. Only checks non-STOPPED deployments.
- **useInstall hook**: Manages full flow — mutation + 3s polling. Phases: `idle` → `installing` → `polling` → `success`/`error`.
- **Install modal**: Multi-step dialog (confirm → progress → success). Used from app cards on the store page.
- **Detail page install**: Inline flow — InstallButton + InstallProgress + InstallSuccess replace the header area.
- **Installed detection**: Store page + detail page fetch deployments alongside catalog data. `installedSlugs` Set passed to cards.
- **Install count**: Incremented in `initiateDeployment()` (fire-and-forget), not in the install API route.

## My Apps Dashboard

- **Route**: `/apps` (grid) + `/apps/[id]` (detail). Old `/deployments` routes redirect to `/apps`.
- **Dependency filtering**: `useMyApps()` filters auto-deployed dependencies by checking which IDs appear in other deployments' `dependsOn` arrays.
- **Query key**: `["my-apps"]` for list, `["my-apps", id]` for detail. Invalidated from install hook, chat provider, remove/restart mutations.
- **Restart**: `POST /api/deployments/[id]/restart` wraps `initiateUpgrade()` with same config.
- **Toast notifications**: Sonner (`sonner@2.0.7`). `<Toaster>` in providers.tsx. `toast.success()` / `toast.error()` for actions.
- **Detail page**: Server component fetches `gettingStarted` from recipe, passes to client `AppDetail` component.
- **Status mapping**: PENDING/DEPLOYING → "Starting..." (yellow pulse), RUNNING → "Running" (green), FAILED → "Needs attention" (red), STOPPED → "Stopped" (gray), DELETING → "Removing..." (yellow pulse).

## App Access & Port-Forwarding

- **Port-forward range**: 10000–10999 (local dev). Ports assigned from DB, tracked on `deployment.localPort`.
- **Port-forward lifecycle**: Worker starts on RUNNING, stops on undeploy/upgrade, health check restarts dead forwards every 60s.
- **Service discovery**: Recipe's `ingressConfig.port` + `ingressConfig.serviceNameSuffix` determine K8s service name/port. Suffix: postgresql→`-postgresql`, redis→`-redis-master`, n8n→`""`, uptime-kuma→`-uptime-kuma`, minio→`-console`.
- **hasWebUI**: Boolean on Recipe. Web UI apps (n8n, Uptime Kuma, MinIO) get "Open" button. Database apps (PostgreSQL, Redis) get "Connection Info" dialog.
- **Connection info API**: `GET /api/deployments/[id]/access` reads K8s secrets + config, returns host/port/credentials/connectionString.
- **Docker port mapping**: Worker container maps `10000-10049:10000-10049` for port-forward access from host.
- **Port-forward process**: `kubectl port-forward svc/<name> <local>:<svc> -n <ns> --address 0.0.0.0` spawned via `child_process.spawn`.

## Frontend Patterns

- **Font**: Inter (not Geist). CSS var `--font-sans`.
- **Providers**: ThemeProvider > QueryClientProvider > TooltipProvider in `src/components/providers.tsx`.
- **Dashboard layout**: `(dashboard)` route group = `/`, `/catalog`, `/apps`, `/settings`. `(onboarding)` route group = `/welcome`.
- **Middleware excludes static assets**: `/icons/*` and common image extensions excluded from auth middleware matcher. Without this, unauthenticated pages (login/signup) can't load public images.
- **Theme hydration**: `useSyncExternalStore` for mounted detection (not useState + useEffect).
- **Sheet accessibility**: Add `<SheetTitle className="sr-only">` + `aria-describedby={undefined}`.
- **Chat events**: `chatEvents.openWithMessage(msg)` from `@/lib/events` — cross-component communication.
- **React Flow v12**: Import from `@xyflow/react`. Explicit type params for `useNodesState<Node>([])`.
- **Canvas polling**: TanStack Query `refetchInterval` returns `false` to disable when no transitional states.

## Package Versions

- next@16.1.6, react@19.2.3, react-dom@19.2.3
- prisma@7.4.0, @prisma/client@7.4.0, @prisma/adapter-pg@7.4.0
- zod@4.3.6, ai@6.0.85, @ai-sdk/react@3.0.88
- next-auth@5.0.0-beta.30 (JWT, credentials only)
- @kubernetes/client-node@1.4.0, bullmq@5.69.1
- @xyflow/react@12.10.0, dagre@0.8.5
- react-markdown@10.1.0, bcryptjs@3.0.3

## Things to Revisit

- Next.js 16 "proxy" convention replacing "middleware" — monitor for when this becomes required
- `ollama-ai-provider` — check for v2 release supporting LanguageModelV3
- Turbopack root warning about multiple lockfiles — mitigated with `turbopack.root: "."` in next.config.ts
